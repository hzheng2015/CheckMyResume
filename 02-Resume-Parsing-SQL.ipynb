{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 8  # plotsize\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.color'] = 'r'\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaner(html,Oneline=True): # return a single line of cleaned text\n",
    "    '''\n",
    "    This function just cleans up the raw html.\n",
    "    Inputs: a URL to investigate\n",
    "    Outputs: Cleaned text only after parsing, tokenization, lemmerization, remove stop-words\n",
    "    '''\n",
    "    try:\n",
    "        site = urllib2.urlopen(html).read() # Connect to the job posting\n",
    "    except:\n",
    "        print \"Error loading \" + html\n",
    "        return   # Need this in case the website isn't there anymore or some other weird connection problem \n",
    "\n",
    "    soup_obj = BeautifulSoup(site,\"lxml\") # Get the html from the site\n",
    "\n",
    "    for script in soup_obj([\"script\", \"style\"]):\n",
    "        script.extract() # Remove these two elements from the BS4 object\n",
    "    \n",
    "    text = soup_obj.body.get_text('\\n') # Get the text from this\n",
    "\n",
    "    lines = (line.strip() for line in text.splitlines()) # break into lines\n",
    "#    lines = [line for i, line in enumerate(lines) if i>16]\n",
    "#    for line in lines:\n",
    "#        print line\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \")) # break multi-headlines into a line each\n",
    "    \n",
    "    def chunk_space(chunk):\n",
    "        chunk_out = chunk + ' ' # Need to fix spacing issue\n",
    "        return chunk_out  \n",
    "\n",
    "    text = ''.join(chunk_space(chunk) for chunk in chunks if chunk).encode('utf-8') # Get rid of all blank lines and ends of line\n",
    "\n",
    "    # Now clean out all of the unicode junk (this line works great!!!)\n",
    "    try:\n",
    "        text = text.decode('unicode_escape').encode('ascii', 'ignore') # Need this as some websites aren't formatted\n",
    "    except:                                                            # in a way that this works, can occasionally throw\n",
    "        return                                                         # an exception\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z+3]\",\" \", text)  # Now get rid of any terms that aren't words (include 3 for d3.js)\n",
    "                                                # Also include + for C++\n",
    "        \n",
    "    # remove the junk from the beginning and end parts of Indeed\n",
    "    try:\n",
    "        text = ((text.lower()).split('advanced search')[1]).split('save resume')[0]\n",
    "    except:\n",
    "        return text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the database to access resume links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>resume_url</th>\n",
       "      <th>job_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.indeed.com/r/Vikas-Patil/d9dc3f1bd6...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.indeed.com/r/Robert-Sousek/f78d89b0...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.indeed.com/me/Kris_I_Ford?sp=0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.indeed.com/r/Joydeep-Singh/ca6d4c0d...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.indeed.com/r/Ahmad-Nahhas/b9b9970cc...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         resume_url       job_class\n",
       "0      0  http://www.indeed.com/r/Vikas-Patil/d9dc3f1bd6...  Data Scientist\n",
       "1      1  http://www.indeed.com/r/Robert-Sousek/f78d89b0...  Data Scientist\n",
       "2      2          http://www.indeed.com/me/Kris_I_Ford?sp=0  Data Scientist\n",
       "3      3  http://www.indeed.com/r/Joydeep-Singh/ca6d4c0d...  Data Scientist\n",
       "4      4  http://www.indeed.com/r/Ahmad-Nahhas/b9b9970cc...  Data Scientist"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = psycopg2.connect(database = 'indeed', user ='hxzheng',host='/tmp/')\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM resume_table2;\n",
    "\"\"\"\n",
    "resumes = pd.read_sql_query(sql_query,con)\n",
    "resumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nresumes = len(resumes['job_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist' 'Software Engineer' 'Consultant' 'Strategy Manager']\n"
     ]
    }
   ],
   "source": [
    "jobclass = resumes['job_class'].unique()\n",
    "print jobclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.indeed.com/r/Vikas-Patil/d9dc3f1bd6af7cbe?sp=0\n",
      "http://www.indeed.com/r/Robert-Sousek/f78d89b06989a308?sp=0\n",
      "http://www.indeed.com/me/Kris_I_Ford?sp=0\n",
      "http://www.indeed.com/r/Joydeep-Singh/ca6d4c0d86888cb1?sp=0\n",
      "http://www.indeed.com/r/Ahmad-Nahhas/b9b9970cc92db421?sp=0\n"
     ]
    }
   ],
   "source": [
    "for i in resumes.index[:5]:\n",
    "    print resumes['resume_url'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.indeed.com/me/Kris_I_Ford?sp=0\n"
     ]
    }
   ],
   "source": [
    "print resumes.ix[2]['resume_url'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print text_cleaner(resumes.ix[0]['resume_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobclass[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>resume_url</th>\n",
       "      <th>job_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.indeed.com/r/Vikas-Patil/d9dc3f1bd6...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.indeed.com/r/Robert-Sousek/f78d89b0...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.indeed.com/me/Kris_I_Ford?sp=0</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.indeed.com/r/Joydeep-Singh/ca6d4c0d...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.indeed.com/r/Ahmad-Nahhas/b9b9970cc...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         resume_url       job_class\n",
       "0      0  http://www.indeed.com/r/Vikas-Patil/d9dc3f1bd6...  Data Scientist\n",
       "1      1  http://www.indeed.com/r/Robert-Sousek/f78d89b0...  Data Scientist\n",
       "2      2          http://www.indeed.com/me/Kris_I_Ford?sp=0  Data Scientist\n",
       "3      3  http://www.indeed.com/r/Joydeep-Singh/ca6d4c0d...  Data Scientist\n",
       "4      4  http://www.indeed.com/r/Ahmad-Nahhas/b9b9970cc...  Data Scientist"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes.loc[resumes['job_class']==jobclass[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Listdict=[]\n",
    "Listindex=[]\n",
    "\n",
    "for i in range(len(jobclass)):\n",
    "    Listindex.append(resumes.loc[resumes['job_class']==jobclass[i]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Listindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "            707, 708, 709, 710, 711, 712, 713, 714, 715, 716],\n",
       "           dtype='int64', length=717)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Listindex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 717,  718,  719,  720,  721,  722,  723,  724,  725,  726,\n",
       "            ...\n",
       "            1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524],\n",
       "           dtype='int64', length=808)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Listindex[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download resumes of Data Scientist etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 100 resumes\n",
      "Done with 200 resumes\n",
      "Done with 300 resumes\n",
      "Done with 400 resumes\n",
      "Done with 500 resumes\n",
      "Done with 600 resumes\n",
      "Done with 700 resumes\n",
      "18.8086180528\n",
      "Done with downloading 717 Data Scientist resumes!\n",
      "Done with 100 resumes\n",
      "Done with 200 resumes\n",
      "Done with 300 resumes\n",
      "Error loading http://www.indeed.com/r/Justin-Towles/be7a202f1b57f08a?sp=0\n",
      "Done with 400 resumes\n",
      "Done with 500 resumes\n",
      "Done with 600 resumes\n",
      "Done with 700 resumes\n",
      "Error loading http://www.indeed.com/r/HALUK-APAYDIN/833435e22e75c26a?sp=0\n",
      "Error loading http://www.indeed.com/r/Kasturi-Hariharasubramanian/014ba91622c04630?sp=0\n",
      "Done with 800 resumes\n",
      "24.7797529141\n",
      "Done with downloading 804 Software Engineer resumes!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resume_file=['Resumes_DS2.txt','Resumes_SE2.txt', 'Resumes_Con2.txt','Resumes_SM2.txt']\n",
    "\n",
    "for jc in range(len(jobclass)):\n",
    "    p=0\n",
    "    t = time.time()\n",
    "    path = '/home/hxzheng/Insight_DS_Fellowship/Project/JobRecomm/Resume_text/'\n",
    "    f = open(path +resume_file[jc],'w') # Write to file\n",
    "    \n",
    "    for i in Listindex[jc]:\n",
    "        link = resumes.ix[i]['resume_url']\n",
    "        try:\n",
    "            text=text_cleaner(link)\n",
    "            if text!=None:\n",
    "                f.write(text+'\\n')  # save to text file\n",
    "                p=p+1\n",
    "        except:\n",
    "            print('Error in accessing resume %d'%i)\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        if p%100==0:\n",
    "            print 'Done with %d resumes'%p  \n",
    "\n",
    "\n",
    "    elapsed = (time.time() - t)/60    \n",
    "    print(elapsed)\n",
    "    print ('Done with downloading %d %s resumes!'%(p,jobclass[jc]))   \n",
    "    f.close()  \n",
    "    time.sleep(120) # to prevent us from overwhelming the Indeed server"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
